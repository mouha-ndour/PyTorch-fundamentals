{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMl9yox2XDOSgV6gXX0u2fD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mouha-ndour/PyTorch-fundamentals/blob/main/PyTorch_in_One_Hour.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I. WAHT IS PYTORCH ?**\n",
        "\n",
        "- An open source Pyhon-based deep learning library.\n",
        "- Pytorch has been the most widely used deep learning library for research papers since 2019 by a wide margin.\n",
        "- One of the reasons Pytorch is so popular is its user-friendly interface and efficiency.\n",
        "\n",
        "**1. The three core components of PyTorch**\n",
        "\n",
        "- Tensor library: that extends the concept of aaray-oriented programming library NumPy with the additional feature of accelerated computation on GPUs, thus providing a seamless swith CPUs and GPUs.\n",
        "- Automatic differentiation engine: alse known as autograd, which enables the automatic computation of gradients for tensor operations, simplifying backpropageion and model optimization."
      ],
      "metadata": {
        "id": "jPO0oLqDj91y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing PyTorch\n",
        "\n",
        "# A leaner version that only supports CPU computing and a\n",
        "# version that supports both CPU and GPU computing.\n",
        "\n",
        "!pip install torch\n",
        "import torch\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "collapsed": true,
        "id": "RF1Gw27usitC",
        "outputId": "a86c6724-d1d7-42c4-c487-f762bebd5016"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.0+cu126'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**II. Understanding tensors**\n",
        "\n",
        "Tensors represent a mathematical concept that generalizes vectorss and matrices to potentially higher dimensions. Tensors are mathemaical objects that can be characterized by their order (or rank), which provides the number of dimensions"
      ],
      "metadata": {
        "id": "5BZkqrhRuq8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalars, vectors, matices, and tensors\n",
        "\n",
        "# We can create objects of PyTORCH's Tensor class using the orch.tensor function as follows:\n",
        "\n",
        "import torch\n",
        "\n",
        "# Create a 0D tensor (scaalar) from a Python integer\n",
        "tensor0d=torch.tensor(1)\n",
        "\n",
        "# Create a 1D tensor(vector) from a python list\n",
        "tensor1d=torch.tensor([1,2,3])\n",
        "\n",
        "# Create a 2D tensor from a nested Python list\n",
        "tensor2d=torch.tensor([[1,2], [3,4]])\n",
        "\n",
        "# create a 3D tensor from a nested Python list\n",
        "tensor3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n"
      ],
      "metadata": {
        "id": "XIlDAuWsuPbV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor data types\n",
        "\n",
        "tensor1d=torch.tensor([1,2,3])\n",
        "print(tensor1d.dtype)\n",
        "\n",
        "# If we create tensors from Python floats, PyTorch creates tensors with a 32-bit precision\n",
        "# by default, as we can see below.\n",
        "floatvec=torch.tensor([1.0,2.0,3.0])\n",
        "print(floatvec.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPOHCidp15nb",
        "outputId": "318a9321-880a-4c9c-e735-0a15a2937aca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0046493"
      },
      "source": [
        "**III. Tensor Data Types**\n",
        "\n",
        "PyTorch tensors can hold data of various types. The choice of data type is crucial as it affects memory consumption, computational speed, and precision. PyTorch supports several data types, including:\n",
        "\n",
        "*   `torch.float32` or `torch.float`: Standard floating-point numbers.\n",
        "*   `torch.float64` or `torch.double`: Double-precision floating-point numbers.\n",
        "*   `torch.int8`: Signed 8-bit integers.\n",
        "*   `torch.int16` or `torch.short`: Signed 16-bit integers.\n",
        "*   `torch.int32` or `torch.int`: Signed 32-bit integers.\n",
        "*   `torch.int64` or `torch.long`: Signed 64-bit integers.\n",
        "*   `torch.bool`: Boolean values (True/False).\n",
        "\n",
        "By default, PyTorch operations often use `torch.float32` for floating-point tensors and `torch.int64` for integer tensors.\n",
        "\n",
        "You can check the data type of a tensor using the `.dtype` attribute and change it using the `.to()` method or `.type()` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "09a78c5e",
        "outputId": "d68203de-b0fe-47ee-86a3-ff9b159907e1"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Create a tensor with default data type (float32)\n",
        "float_tensor = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(f\"Default float tensor: {float_tensor} | Data type: {float_tensor.dtype}\")\n",
        "\n",
        "# Create an integer tensor with default data type (int64)\n",
        "int_tensor = torch.tensor([1, 2, 3])\n",
        "print(f\"Default integer tensor: {int_tensor} | Data type: {int_tensor.dtype}\")\n",
        "\n",
        "# Specify a data type during creation\n",
        "int16_tensor = torch.tensor([1, 2, 3], dtype=torch.int16)\n",
        "print(f\"Int16 tensor: {int16_tensor} | Data type: {int16_tensor.dtype}\")\n",
        "\n",
        "# Change the data type using .to()\n",
        "float64_tensor = float_tensor.to(torch.float64)\n",
        "print(f\"Float64 tensor: {float64_tensor} | Data type: {float64_tensor.dtype}\")\n",
        "\n",
        "# Change the data type using .type()\n",
        "int_from_float = float_tensor.type(torch.int32)\n",
        "print(f\"Int32 tensor from float: {int_from_float} | Data type: {int_from_float.dtype}\")\n",
        "\n",
        "# Create a boolean tensor\n",
        "bool_tensor = torch.tensor([True, False, True])\n",
        "print(f\"Boolean tensor: {bool_tensor} | Data type: {bool_tensor.dtype}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default float tensor: tensor([1., 2., 3.]) | Data type: torch.float32\n",
            "Default integer tensor: tensor([1, 2, 3]) | Data type: torch.int64\n",
            "Int16 tensor: tensor([1, 2, 3], dtype=torch.int16) | Data type: torch.int16\n",
            "Float64 tensor: tensor([1., 2., 3.], dtype=torch.float64) | Data type: torch.float64\n",
            "Int32 tensor from float: tensor([1, 2, 3], dtype=torch.int32) | Data type: torch.int32\n",
            "Boolean tensor: tensor([ True, False,  True]) | Data type: torch.bool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Common PyTorch tensor operations\n",
        "\n",
        "tensor2d=torch.tensor([[1,2,3], [4,5,6]])\n",
        "tensor2d\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZzMSlgl3VH5",
        "outputId": "4bf474bb-2a61-4a68-edd6-8fa0fe527fbf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The .shape attribute allows us to access the shape of a tensor\n",
        "print(tensor2d.shape)\n",
        "\n",
        "# Note that the more common command for reshaping tensors in PyTorch is\n",
        "# .view\n",
        "tensor2d.view(3,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9FwXnAyY5EoI",
        "outputId": "ddad887c-fc34-45ec-dc35-3863ae3a81ad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IV- SEEING MODELS AS COMPUTATION GRAPHS**\n",
        "\n",
        "\n",
        "In the previous section, we covered one of the major three components of PyTorch, namely, its tensor library. Next in line is PyTorch's automatic differenctiation engine, also known as autograd. Before we dive deeper into computing gradients in the next section, let's define the concept of a computational graph.\n",
        "\n",
        "A computational graph is a directed graph that allows us to express andvisualize mathematical expressions. In the context of deep learning, a computation graph lays ou the sequence of calculations neede to compute the output of a neural networks.\n",
        "\n",
        "Let's look at a concrete example to illustrate the concept of a computation graph: a simple logistic regression classifier (which can be seen as single layer neural network)."
      ],
      "metadata": {
        "id": "QskLXjal2B9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "y=torch.tensor([1.0])\n",
        "x1=torch.tensor([1.1])\n",
        "w1=torch.tensor([2.2])\n",
        "b=torch.tensor([0.0])\n",
        "\n",
        "z=x1*w1 + b # net input\n",
        "a=torch.sigmoid(z) # activation & output\n",
        "loss=F.binary_cross_entropy(a, y)\n",
        "print(loss)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URNGr_sn0Tjm",
        "outputId": "3e51a050-200b-4cfa-9230-f223ebf78ca2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0852)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**V. AUTOMATIC DIFFERENTIATION MADE EASY**\n",
        "\n",
        "\n",
        "- requires_grad := In the previous section, we introduced the concept of computation graphs. If we carry out computations in PyTorch, it will build such a graph internally by default if one of its terminal nodes has the requires_grad attribute set to True. This is useful if we want to compute gradients. Gradients are required when training neural networks via the popular backpropagation algorithm, which can be thought of as an implementation of the chain rule from calculus for neural networks\n",
        "\n",
        "- retain_graph :=By default, PyTorch destroys the computation graph after calculating the gradients to free memory. However, since we are going to reuse this computation graph shortly, we set retain_graph=True so that it stays in memory.\n",
        "\n",
        "- .backward :=\n",
        "- .grad := We can call .backward on the loss, and PyTorch will compute the gradients of all the leaf nodes in the graph, which will be stored via the tensors’ .grad attributes:"
      ],
      "metadata": {
        "id": "Fjbg6Ii4EEvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.autograd import grad\n",
        "\n",
        "y=torch.tensor([1.0])\n",
        "x1=torch.tensor([1.1])\n",
        "w1=torch.tensor([2.2], requires_grad=True)\n",
        "b=torch.tensor([0.0], requires_grad=True)\n",
        "\n",
        "z=x1*w1 + b\n",
        "a=torch.sigmoid(z)\n",
        "\n",
        "loss=F.binary_cross_entropy(a, y)\n",
        "\n",
        "grad_L_w1= grad(loss, w1, retain_graph=True)\n",
        "grad_L_b= grad(loss, b, retain_graph=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "7cZCchriDA6e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "\n",
        "print(w1.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pCE2Jc4CczG",
        "outputId": "029cf145-9dbc-4b13-e664-c51bbcd057ea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0898])\n",
            "tensor([-0.0817])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VI. IMPLEMENTING MULTILAYER NEURAL NETWORKS**\n",
        "\n"
      ],
      "metadata": {
        "id": "DDk_4xupDhcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(torch.nn.Module):\n",
        "  def __init__(self, num_inputs, num_outputs):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layers = torch.nn.Sequential(\n",
        "\n",
        "                                      # 1st hidden layer\n",
        "                                      torch.nn.Linear(num_inputs, 30),\n",
        "                                      torch.nn.ReLU(),\n",
        "\n",
        "                                      # 2nd hidden layer\n",
        "                                      torch.nn.Linear(30, 20),\n",
        "                                      torch.nn.ReLU(),\n",
        "\n",
        "                                      # output layer\n",
        "                                      torch.nn.Linear(20, num_outputs),\n",
        "\n",
        "       )\n",
        "\n",
        "  def forward(self, x):\n",
        "    logits = self.layers(x)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "XJbhJY4qIJWQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can then instantiate a new neural network object as follows:\n",
        "model = NeuralNetwork(50, 3)\n",
        "\n",
        "# Let's see the summary of its structure\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVRj0alWQmr6",
        "outputId": "7bd80577-248a-49a3-91ca-0eb446c58675"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's check the total number of trainable parameters of this model\n",
        "num_params = sum(\n",
        "    p.numel() for p in model.parameters() if p.requires_grad\n",
        ")\n",
        "\n",
        "print(\"Total number of trainable model parameters:\", num_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XLyQT_7RT4N",
        "outputId": "c48d8ce5-5c28-4676-c243-7b6793b177b9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of trainable model parameters: 2213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Based on the print(model) call we executed above, we can see that the first\n",
        "# Linear layer is at index position 0 in the layers attribute. We can access the corresponding weight parameter matrix as follows:\n",
        "\n",
        "print(model.layers[0].weight)\n",
        "print(model.layers[0].weight.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BdI3JApcUFnb",
        "outputId": "ca81a839-a96a-4770-8146-fdde30f0d8b4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.1391, -0.1022,  0.0838,  ...,  0.1101, -0.0009,  0.0779],\n",
            "        [ 0.0293, -0.0160,  0.0398,  ...,  0.0220,  0.0436, -0.1319],\n",
            "        [-0.1135,  0.1195, -0.0367,  ..., -0.0077, -0.0801, -0.0291],\n",
            "        ...,\n",
            "        [ 0.0975, -0.0606, -0.1159,  ..., -0.0106,  0.0931, -0.0603],\n",
            "        [ 0.0867, -0.1358, -0.0711,  ...,  0.1199,  0.1392,  0.1003],\n",
            "        [-0.0667,  0.0932,  0.0806,  ...,  0.1332,  0.0578,  0.0098]],\n",
            "       requires_grad=True)\n",
            "torch.Size([30, 50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "model = NeuralNetwork(50, 3)\n",
        "print(model.layers[0].weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZubpyZ0VXwW9",
        "outputId": "f7915c4c-9879-4032-a94d-84068fe20f01"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0577,  0.0047, -0.0702,  ...,  0.0222,  0.1260,  0.0865],\n",
            "        [ 0.0502,  0.0307,  0.0333,  ...,  0.0951,  0.1134, -0.0297],\n",
            "        [ 0.1077, -0.1108,  0.0122,  ...,  0.0108, -0.1049, -0.1063],\n",
            "        ...,\n",
            "        [-0.0787,  0.1259,  0.0803,  ...,  0.1218,  0.1303, -0.1351],\n",
            "        [ 0.1359,  0.0175, -0.0673,  ...,  0.0674,  0.0676,  0.1058],\n",
            "        [ 0.0790,  0.1343, -0.0293,  ...,  0.0344, -0.0971, -0.0509]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "X=torch.rand((1, 50))\n",
        "out=model(X)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPm8Gx25Z18F",
        "outputId": "c3da9de2-c1ad-4a11-aa23-046757eae690"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1262,  0.1080, -0.1792]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  out = model(X)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ljicr65rcmrj",
        "outputId": "e4e8d7b4-a867-4d0c-9d6d-c61cd556dda1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1262,  0.1080, -0.1792]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  out = torch.softmax(model(X), dim=1)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gq1eBKCc5Wo",
        "outputId": "4a36149e-1861-4454-da02-1070625d289a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3113, 0.3934, 0.2952]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s start by creating a simple toy dataset of five training examples with two features each. Accompanying the training examples, we also create a tensor containing the corresponding class labels: three examples belong to class 0, and two examples belong to class 1. In addition, we also make a test set consisting of two entries. The code to create this dataset is shown below."
      ],
      "metadata": {
        "id": "hCoA6e-2Kng4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train = torch.tensor([\n",
        "    [-1.2, 3.1],\n",
        "    [-0.9, 2.9],\n",
        "    [-0.5, 2.6],\n",
        "    [2.3, -1.1],\n",
        "    [2.7, -1.5]\n",
        "])\n",
        "\n",
        "y_train = torch.tensor([0, 0, 0, 1, 1])\n",
        "\n",
        "X_test = torch.tensor([\n",
        "    [-0.8, 2.8],\n",
        "    [2.6, -1.6],\n",
        "])\n",
        "\n",
        "y_test = torch.tensor([0, 1])"
      ],
      "metadata": {
        "id": "vVh53mA-_vPw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, wee create a custom dataset class, ToyDataset, by subclassing from PyTorch'sDataset parent class, as shown below."
      ],
      "metadata": {
        "id": "06-Q6hGMPUg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ToyDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.features = X\n",
        "    self.labels = y\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    one_x = self.features[index]\n",
        "    one_y = self.labels[index]\n",
        "    return one_x, one_y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.labels.shape[0]\n",
        "\n",
        "train_ds = ToyDataset(X_train, y_train)\n",
        "test_ds = ToyDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "n9fc6ZdqLwZU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This custom ToyDataset class’s purpose is to use it to instantiate a PyTorch DataLoader. But before we get to this step, let’s briefly go over the general structure of the ToyDataset code.\n",
        "\n",
        "In PyTorch, the three main components of a custom Dataset class are the __init__ constructor, the __getitem__ method, and the __len__ method, as shown in code ToyDataset code above.\n",
        "\n",
        "In the __init__ method, we set up attributes that we can access later in the __getitem__ and __len__ methods. This could be file paths, file objects, database connectors, and so on. Since we created a tensor dataset that sits in memory, we are simply assigning X and y to these attributes, which are placeholders for our tensor objects.\n",
        "\n",
        "In the __getitem__ method, we define instructions for returning exactly one item from the dataset via an index. This means the features and the class label corresponding to a single training example or test instance. (The data loader will provide this index, which we will cover shortly.)\n",
        "\n",
        "Finally, the __len__ method contains instructions for retrieving the length of the dataset. Here, we use the .shape attribute of a tensor to return the number of rows in the feature array. In the case of the training dataset, we have five rows, which we can double-check as follows:"
      ],
      "metadata": {
        "id": "KHHEP8qsVy0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "ou5Z3fRCQqIf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "test_loader=DataLoader(\n",
        "    dataset=test_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "wQn9aXLiYgXj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    dataset=train_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    drop_last=True\n",
        ")"
      ],
      "metadata": {
        "id": "UhoXlzrypeIr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For iterating over the training loader, we can see that the last batch is omitted\n",
        "\n",
        "for idx, (x,y) in enumerate(train_loader):\n",
        "  print(f\"Batch {idx}:\", x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xdq75mn_ptrb",
        "outputId": "e0c4916c-8787-4205-f63b-477c3c580f8b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0: tensor([[ 2.3000, -1.1000],\n",
            "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
            "Batch 1: tensor([[-1.2000,  3.1000],\n",
            "        [-0.5000,  2.6000]]) tensor([0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VIII. A typical training loop**\n",
        "\n",
        "So far, we’ve discussed all the requirements for training neural networks: PyTorch’s tensor library, autograd, the Module API, and efficient data loaders. Let’s now combine all these things and train a neural network on the toy dataset from the previous section. The training code is shown in code below."
      ],
      "metadata": {
        "id": "WOUh9iQgqTze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model=NeuralNetwork(num_inputs=2, num_outputs=2)\n",
        "optimizer=torch.optim.SGD(model.parameters(), lr=0.5)\n",
        "\n",
        "num_epochs=3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  for batch_idx, (features, labels) in enumerate(train_loader):\n",
        "\n",
        "    logits=model(features)\n",
        "\n",
        "    loss=F.cross_entropy(logits, labels)  # Loss function\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    ### LOGGING\n",
        "    print(f\"Epoch: {epoch}/{num_epochs:03d}\"\n",
        "          f\" | Batch {batch_idx:03d}/{len(train_loader):03d}\"\n",
        "          f\" | Train/Val Loss: {loss:.2f}\"\n",
        "    )\n",
        "\n",
        "    model.eval()\n",
        "    # Optional model evaluation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQutVZmgqRKR",
        "outputId": "c01c31fa-1b36-4b26-e70e-dd5fe70563bb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0/003 | Batch 000/002 | Train/Val Loss: 0.75\n",
            "Epoch: 0/003 | Batch 001/002 | Train/Val Loss: 0.65\n",
            "Epoch: 1/003 | Batch 000/002 | Train/Val Loss: 0.44\n",
            "Epoch: 1/003 | Batch 001/002 | Train/Val Loss: 0.13\n",
            "Epoch: 2/003 | Batch 000/002 | Train/Val Loss: 0.03\n",
            "Epoch: 2/003 | Batch 001/002 | Train/Val Loss: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the loss reaches zero after 3 epochs, a sign that the model converged on the training set. However, before we evaluate the model’s predictions, let’s go over some of the details of the preceding code.\n",
        "\n",
        "First, note that we initialized a model with two inputs and two outputs. That’s because the toy dataset from the previous section has two input features and two class labels to predict. We used a stochastic gradient descent (SGD) optimizer with a learning rate (lr) of 0.5. The learning rate is a hyperparameter, meaning it’s a tunable setting that we have to experiment with based on observing the loss. Ideally, we want to choose a learning rate such that the loss converges after a certain number of epochs – the number of epochs is another hyperparameter to choose.\n",
        "\n",
        "In practice, we often use a third dataset, a so-called validation dataset, to find the optimal hyperparameter settings. A validation dataset is similar to a test set. However, while we only want to use a test set precisely once to avoid biasing the evaluation, we usually use the validation set multiple times to tweak the model settings.\n",
        "\n",
        "We also introduced new settings called model.train() and model.eval(). As these names imply, these settings are used to put the model into a training and an evaluation mode. This is necessary for components that behave differently during training and inference, such as dropout or batch normalization layers. Since we don’t have dropout or other components in our NeuralNetwork class that are affected by these settings, using model.train() and model.eval() is redundant in our code above. However, it’s best practice to include them anyway to avoid unexpected behaviors when we change the model architecture or reuse the code to train a different model.\n",
        "\n",
        "As discussed earlier, we pass the logits directly into the cross_entropy loss function, which will apply the softmax function internally for efficiency and numerical stability reasons. Then, calling loss.backward() will calculate the gradients in the computation graph that PyTorch constructed in the background. The optimizer.step() method will use the gradients to update the model parameters to minimize the loss. In the case of the SGD optimizer, this means multiplying the gradients with the learning rate and adding the scaled negative gradient to the parameters."
      ],
      "metadata": {
        "id": "J1HNJUK9yXaL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oz2a3JVWyb2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preventing undesired gradient accumulation**\n",
        "\n",
        "It is important to include an optimizer.zero_grad() call in each update round to reset the gradients to zero. Otherwise, the gradients will accumulate, which may be undesired."
      ],
      "metadata": {
        "id": "Bpkf6QmRyg0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs=model(X_train)\n",
        "\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mCLM-sVyr1x",
        "outputId": "288f7d88-2977-4baa-b4e1-e14f2daf6be3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.8569, -4.1618],\n",
            "        [ 2.5382, -3.7548],\n",
            "        [ 2.0944, -3.1820],\n",
            "        [-1.4814,  1.4816],\n",
            "        [-1.7176,  1.7342]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To obtain the class memership probabilities, we can use PytOrch's softmax function, as follows:\n",
        "\n",
        "torch.set_printoptions(sci_mode=False)\n",
        "probas=torch.softmax(outputs, dim=1)\n",
        "print(probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRIncgpyzNuB",
        "outputId": "b9a5a698-f58c-4ffc-97c5-c54923039459"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9991, 0.0009],\n",
            "        [0.9982, 0.0018],\n",
            "        [0.9949, 0.0051],\n",
            "        [0.0491, 0.9509],\n",
            "        [0.0307, 0.9693]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can convert these values into class labels predictions using\n",
        "# PyTorch's argmax function, which returns the index position of the highest value in each row\n",
        "# if we set dim=1 (setting dim=0 would return the highest value in each column, instead)\n",
        "\n",
        "predictions=torch.argmax(probas, dim=1)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jrDB3vx2J0J",
        "outputId": "3a2e859f-2300-48ce-b529-9e2da8652202"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# It's unnecessary to compute softmax probas to obtain the class\n",
        "# labels. We could also apply the argmax function to the logits (outputs) directly\n",
        "\n",
        "predictions=torch.argmax(outputs, dim=1)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1pffd1x3J4H",
        "outputId": "64c99a5e-d246-43de-8358-80b9f67bd6a0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using torch.sum, we can count the number of correct prediction as follows:\n",
        "\n",
        "torch.sum(predictions == y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI2MDqct4GfW",
        "outputId": "8fac7ac8-21a4-4b92-94f1-c5a6e78b8300"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Note that the following compute_accuracy function iterates over a data loader to compute the number and fraction of the correct predictions. This is because when we work with large datasets, we typically can only call the model on a small part of the dataset due to memory limitations. The compute_accuracy function above is a general method that scales to datasets of arbitrary size since, in each iteration, the dataset chunk that the model receives is the same size as the batch size seen during training.\n",
        "\n",
        "Notice that the internals of the compute_accuracy function are similar to what we used before when we converted the logits to the class labels."
      ],
      "metadata": {
        "id": "EHVLgB4V4lq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(model, dataloader):\n",
        "\n",
        "  model=model.eval()\n",
        "  correct=0.0\n",
        "  total_examples=0\n",
        "\n",
        "  for idx, (features, labels) in enumerate(dataloader):\n",
        "\n",
        "    with torch.no_grad():\n",
        "      logits=model(features)\n",
        "\n",
        "    predictions=torch.argmax(logits, dim=1)\n",
        "    compare = (labels == predictions) # Compare labels and predictions\n",
        "    correct += torch.sum(compare).item() # Sum the True values (correct predictions)\n",
        "    total_examples += len(labels) # Add the number of examples in the current batch\n",
        "\n",
        "  return (correct / total_examples).item()"
      ],
      "metadata": {
        "id": "2RP9UazS4ydA"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}