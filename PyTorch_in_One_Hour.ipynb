{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM7/tzyajRvdfr3BSp9uccX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mouha-ndour/PyTorch-fundamentals/blob/main/PyTorch_in_One_Hour.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I. WAHT IS PYTORCH ?**\n",
        "\n",
        "- An open source Pyhon-based deep learning library.\n",
        "- Pytorch has been the most widely used deep learning library for research papers since 2019 by a wide margin.\n",
        "- One of the reasons Pytorch is so popular is its user-friendly interface and efficiency.\n",
        "\n",
        "**1. The three core components of PyTorch**\n",
        "\n",
        "- Tensor library: that extends the concept of aaray-oriented programming library NumPy with the additional feature of accelerated computation on GPUs, thus providing a seamless swith CPUs and GPUs.\n",
        "- Automatic differentiation engine: alse known as autograd, which enables the automatic computation of gradients for tensor operations, simplifying backpropageion and model optimization."
      ],
      "metadata": {
        "id": "jPO0oLqDj91y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing PyTorch\n",
        "\n",
        "# A leaner version that only supports CPU computing and a\n",
        "# version that supports both CPU and GPU computing.\n",
        "\n",
        "!pip install torch\n",
        "import torch\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "collapsed": true,
        "id": "RF1Gw27usitC",
        "outputId": "8043b6fc-5e3e-4b6a-eaa9-127f603043c6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0+cu126'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**II. Understanding tensors**\n",
        "\n",
        "Tensors represent a mathematical concept that generalizes vectorss and matrices to potentially higher dimensions. Tensors are mathemaical objects that can be characterized by their order (or rank), which provides the number of dimensions"
      ],
      "metadata": {
        "id": "5BZkqrhRuq8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalars, vectors, matices, and tensors\n",
        "\n",
        "# We can create objects of PyTORCH's Tensor class using the orch.tensor function as follows:\n",
        "\n",
        "import torch\n",
        "\n",
        "# Create a 0D tensor (scaalar) from a Python integer\n",
        "tensor0d=torch.tensor(1)\n",
        "\n",
        "# Create a 1D tensor(vector) from a python list\n",
        "tensor1d=torch.tensor([1,2,3])\n",
        "\n",
        "# Create a 2D tensor from a nested Python list\n",
        "tensor2d=torch.tensor([[1,2], [3,4]])\n",
        "\n",
        "# create a 3D tensor from a nested Python list\n",
        "tensor3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n"
      ],
      "metadata": {
        "id": "XIlDAuWsuPbV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor data types\n",
        "\n",
        "tensor1d=torch.tensor([1,2,3])\n",
        "print(tensor1d.dtype)\n",
        "\n",
        "# If we create tensors from Python floats, PyTorch creates tensors with a 32-bit precision\n",
        "# by default, as we can see below.\n",
        "floatvec=torch.tensor([1.0,2.0,3.0])\n",
        "print(floatvec.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPOHCidp15nb",
        "outputId": "e0770a5f-f35a-4075-f3f6-514e7579c92f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0046493"
      },
      "source": [
        "**III. Tensor Data Types**\n",
        "\n",
        "PyTorch tensors can hold data of various types. The choice of data type is crucial as it affects memory consumption, computational speed, and precision. PyTorch supports several data types, including:\n",
        "\n",
        "*   `torch.float32` or `torch.float`: Standard floating-point numbers.\n",
        "*   `torch.float64` or `torch.double`: Double-precision floating-point numbers.\n",
        "*   `torch.int8`: Signed 8-bit integers.\n",
        "*   `torch.int16` or `torch.short`: Signed 16-bit integers.\n",
        "*   `torch.int32` or `torch.int`: Signed 32-bit integers.\n",
        "*   `torch.int64` or `torch.long`: Signed 64-bit integers.\n",
        "*   `torch.bool`: Boolean values (True/False).\n",
        "\n",
        "By default, PyTorch operations often use `torch.float32` for floating-point tensors and `torch.int64` for integer tensors.\n",
        "\n",
        "You can check the data type of a tensor using the `.dtype` attribute and change it using the `.to()` method or `.type()` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "09a78c5e",
        "outputId": "6ccb639c-9278-4c00-9f8e-383564642be8"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Create a tensor with default data type (float32)\n",
        "float_tensor = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(f\"Default float tensor: {float_tensor} | Data type: {float_tensor.dtype}\")\n",
        "\n",
        "# Create an integer tensor with default data type (int64)\n",
        "int_tensor = torch.tensor([1, 2, 3])\n",
        "print(f\"Default integer tensor: {int_tensor} | Data type: {int_tensor.dtype}\")\n",
        "\n",
        "# Specify a data type during creation\n",
        "int16_tensor = torch.tensor([1, 2, 3], dtype=torch.int16)\n",
        "print(f\"Int16 tensor: {int16_tensor} | Data type: {int16_tensor.dtype}\")\n",
        "\n",
        "# Change the data type using .to()\n",
        "float64_tensor = float_tensor.to(torch.float64)\n",
        "print(f\"Float64 tensor: {float64_tensor} | Data type: {float64_tensor.dtype}\")\n",
        "\n",
        "# Change the data type using .type()\n",
        "int_from_float = float_tensor.type(torch.int32)\n",
        "print(f\"Int32 tensor from float: {int_from_float} | Data type: {int_from_float.dtype}\")\n",
        "\n",
        "# Create a boolean tensor\n",
        "bool_tensor = torch.tensor([True, False, True])\n",
        "print(f\"Boolean tensor: {bool_tensor} | Data type: {bool_tensor.dtype}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default float tensor: tensor([1., 2., 3.]) | Data type: torch.float32\n",
            "Default integer tensor: tensor([1, 2, 3]) | Data type: torch.int64\n",
            "Int16 tensor: tensor([1, 2, 3], dtype=torch.int16) | Data type: torch.int16\n",
            "Float64 tensor: tensor([1., 2., 3.], dtype=torch.float64) | Data type: torch.float64\n",
            "Int32 tensor from float: tensor([1, 2, 3], dtype=torch.int32) | Data type: torch.int32\n",
            "Boolean tensor: tensor([ True, False,  True]) | Data type: torch.bool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Common PyTorch tensor operations\n",
        "\n",
        "tensor2d=torch.tensor([[1,2,3], [4,5,6]])\n",
        "tensor2d\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZzMSlgl3VH5",
        "outputId": "b104fb8a-3bfc-4108-eb82-43209de3d4da"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The .shape attribute allows us to access the shape of a tensor\n",
        "print(tensor2d.shape)\n",
        "\n",
        "# Note that the more common command for reshaping tensors in PyTorch is\n",
        "# .view\n",
        "tensor2d.view(3,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9FwXnAyY5EoI",
        "outputId": "9a9f43a2-c0b2-435c-a92e-2701eb715e0c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IV- SEEING MODELS AS COMPUTATION GRAPHS**\n",
        "\n",
        "\n",
        "In the previous section, we covered one of the major three components of PyTorch, namely, its tensor library. Next in line is PyTorch's automatic differenctiation engine, also known as autograd. Before we dive deeper into computing gradients in the next section, let's define the concept of a computational graph.\n",
        "\n",
        "A computational graph is a directed graph that allows us to express andvisualize mathematical expressions. In the context of deep learning, a computation graph lays ou the sequence of calculations neede to compute the output of a neural networks.\n",
        "\n",
        "Let's look at a concrete example to illustrate the concept of a computation graph: a simple logistic regression classifier (which can be seen as single layer neural network)."
      ],
      "metadata": {
        "id": "QskLXjal2B9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "y=torch.tensor([1.0])\n",
        "x1=torch.tensor([1.1])\n",
        "w1=torch.tensor([2.2])\n",
        "b=torch.tensor([0.0])\n",
        "\n",
        "z=x1*w1 + b # net input\n",
        "a=torch.sigmoid(z) # activation & output\n",
        "loss=F.binary_cross_entropy(a, y)\n",
        "print(loss)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URNGr_sn0Tjm",
        "outputId": "7ccfe156-0aec-468c-d3fe-29e28040dea1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0852)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**V. AUTOMATIC DIFFERENTIATION MADE EASY**\n",
        "\n",
        "\n",
        "- requires_grad := In the previous section, we introduced the concept of computation graphs. If we carry out computations in PyTorch, it will build such a graph internally by default if one of its terminal nodes has the requires_grad attribute set to True. This is useful if we want to compute gradients. Gradients are required when training neural networks via the popular backpropagation algorithm, which can be thought of as an implementation of the chain rule from calculus for neural networks\n",
        "\n",
        "- retain_graph :=By default, PyTorch destroys the computation graph after calculating the gradients to free memory. However, since we are going to reuse this computation graph shortly, we set retain_graph=True so that it stays in memory.\n",
        "\n",
        "- .backward :=\n",
        "- .grad := We can call .backward on the loss, and PyTorch will compute the gradients of all the leaf nodes in the graph, which will be stored via the tensors’ .grad attributes:"
      ],
      "metadata": {
        "id": "Fjbg6Ii4EEvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.autograd import grad\n",
        "\n",
        "y=torch.tensor([1.0])\n",
        "x1=torch.tensor([1.1])\n",
        "w1=torch.tensor([2.2], requires_grad=True)\n",
        "b=torch.tensor([0.0], requires_grad=True)\n",
        "\n",
        "z=x1*w1 + b\n",
        "a=torch.sigmoid(z)\n",
        "\n",
        "loss=F.binary_cross_entropy(a, y)\n",
        "\n",
        "grad_L_w1= grad(loss, w1, retain_graph=True)\n",
        "grad_L_b= grad(loss, b, retain_graph=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "7cZCchriDA6e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "\n",
        "print(w1.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pCE2Jc4CczG",
        "outputId": "2f7f7f82-6e76-4a2a-b942-1bec2fede8a4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0898])\n",
            "tensor([-0.0817])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VI. IMPLEMENTING MULTILAYER NEURAL NETWORKS**\n",
        "\n"
      ],
      "metadata": {
        "id": "DDk_4xupDhcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(torch.nn.Module):\n",
        "  def __init__(self, num_inputs, num_outputs):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layers = torch.nn.Sequential(\n",
        "\n",
        "                                      # 1st hidden layer\n",
        "                                      torch.nn.Linear(num_inputs, 30),\n",
        "                                      torch.nn.ReLU(),\n",
        "\n",
        "                                      # 2nd hidden layer\n",
        "                                      torch.nn.Linear(30, 20),\n",
        "                                      torch.nn.ReLU(),\n",
        "\n",
        "                                      # output layer\n",
        "                                      torch.nn.Linear(20, num_outputs),\n",
        "\n",
        "       )\n",
        "\n",
        "  def forward(self, x):\n",
        "    logits = self.layers(x)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "XJbhJY4qIJWQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can then instantiate a new neural network object as follows:\n",
        "model = NeuralNetwork(50, 3)\n",
        "\n",
        "# Let's see the summary of its structure\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVRj0alWQmr6",
        "outputId": "57be667b-cca7-4053-a02d-8bfff66e0b79"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's check the total number of trainable parameters of this model\n",
        "num_params = sum(\n",
        "    p.numel() for p in model.parameters() if p.requires_grad\n",
        ")\n",
        "\n",
        "print(\"Total number of trainable model parameters:\", num_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XLyQT_7RT4N",
        "outputId": "616e5eb2-4e68-4cbb-f81c-599338954416"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of trainable model parameters: 2213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Based on the print(model) call we executed above, we can see that the first\n",
        "# Linear layer is at index position 0 in the layers attribute. We can access the corresponding weight parameter matrix as follows:\n",
        "\n",
        "print(model.layers[0].weight)\n",
        "print(model.layers[0].weight.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BdI3JApcUFnb",
        "outputId": "be751584-f252-47bd-e89e-9d99e1f1975a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0456, -0.0141,  0.0761,  ..., -0.0324, -0.0042,  0.1161],\n",
            "        [ 0.0323,  0.1321, -0.1145,  ...,  0.0313, -0.0374,  0.0726],\n",
            "        [ 0.0972, -0.0297, -0.0370,  ...,  0.0319, -0.1087,  0.0325],\n",
            "        ...,\n",
            "        [-0.1201,  0.0165, -0.0224,  ...,  0.1244, -0.1190, -0.0560],\n",
            "        [ 0.0922, -0.1121,  0.0968,  ..., -0.0456,  0.0201,  0.0638],\n",
            "        [-0.0840,  0.0378,  0.1035,  ..., -0.0011,  0.1358, -0.1325]],\n",
            "       requires_grad=True)\n",
            "torch.Size([30, 50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "model = NeuralNetwork(50, 3)\n",
        "print(model.layers[0].weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZubpyZ0VXwW9",
        "outputId": "6f577bcf-bcf1-4d03-e89b-8053fa90ee79"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0577,  0.0047, -0.0702,  ...,  0.0222,  0.1260,  0.0865],\n",
            "        [ 0.0502,  0.0307,  0.0333,  ...,  0.0951,  0.1134, -0.0297],\n",
            "        [ 0.1077, -0.1108,  0.0122,  ...,  0.0108, -0.1049, -0.1063],\n",
            "        ...,\n",
            "        [-0.0787,  0.1259,  0.0803,  ...,  0.1218,  0.1303, -0.1351],\n",
            "        [ 0.1359,  0.0175, -0.0673,  ...,  0.0674,  0.0676,  0.1058],\n",
            "        [ 0.0790,  0.1343, -0.0293,  ...,  0.0344, -0.0971, -0.0509]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "X=torch.rand((1, 50))\n",
        "out=model(X)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPm8Gx25Z18F",
        "outputId": "68c0864e-90da-437e-ed87-242296c297fb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1262,  0.1080, -0.1792]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  out = model(X)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ljicr65rcmrj",
        "outputId": "b2bca086-6bab-4917-94d5-5eaf5183976a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1262,  0.1080, -0.1792]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  out = torch.softmax(model(X), dim=1)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gq1eBKCc5Wo",
        "outputId": "981918d8-f526-47fe-dcb9-66ff8832d0a1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3113, 0.3934, 0.2952]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s start by creating a simple toy dataset of five training examples with two features each. Accompanying the training examples, we also create a tensor containing the corresponding class labels: three examples belong to class 0, and two examples belong to class 1. In addition, we also make a test set consisting of two entries. The code to create this dataset is shown below."
      ],
      "metadata": {
        "id": "hCoA6e-2Kng4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train = torch.tensor([\n",
        "    [-1.2, 3.1],\n",
        "    [-0.9, 2.9],\n",
        "    [-0.5, 2.6],\n",
        "    [2.3, -1.1],\n",
        "    [2.7, -1.5]\n",
        "])\n",
        "\n",
        "y_train = torch.tensor([0, 0, 0, 1, 1])\n",
        "\n",
        "X_test = torch.tensor([\n",
        "    [-0.8, 2.8],\n",
        "    [2.6, -1.6],\n",
        "])\n",
        "\n",
        "y_test = torch.tensor([0, 1])"
      ],
      "metadata": {
        "id": "vVh53mA-_vPw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, wee create a custom dataset class, ToyDataset, by subclassing from PyTorch'sDataset parent class, as shown below."
      ],
      "metadata": {
        "id": "06-Q6hGMPUg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ToyDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.features = X\n",
        "    self.labels = y\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    one_x = self.features[index]\n",
        "    one_y = self.labels[index]\n",
        "    return one_x, one_y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.labels.shape[0]\n",
        "\n",
        "train_ds = ToyDataset(X_train, y_train)\n",
        "test_ds = ToyDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "n9fc6ZdqLwZU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This custom ToyDataset class’s purpose is to use it to instantiate a PyTorch DataLoader. But before we get to this step, let’s briefly go over the general structure of the ToyDataset code.\n",
        "\n",
        "In PyTorch, the three main components of a custom Dataset class are the __init__ constructor, the __getitem__ method, and the __len__ method, as shown in code ToyDataset code above.\n",
        "\n",
        "In the __init__ method, we set up attributes that we can access later in the __getitem__ and __len__ methods. This could be file paths, file objects, database connectors, and so on. Since we created a tensor dataset that sits in memory, we are simply assigning X and y to these attributes, which are placeholders for our tensor objects.\n",
        "\n",
        "In the __getitem__ method, we define instructions for returning exactly one item from the dataset via an index. This means the features and the class label corresponding to a single training example or test instance. (The data loader will provide this index, which we will cover shortly.)\n",
        "\n",
        "Finally, the __len__ method contains instructions for retrieving the length of the dataset. Here, we use the .shape attribute of a tensor to return the number of rows in the feature array. In the case of the training dataset, we have five rows, which we can double-check as follows:"
      ],
      "metadata": {
        "id": "KHHEP8qsVy0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "ou5Z3fRCQqIf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "test_loader=DataLoader(\n",
        "    dataset=test_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "wQn9aXLiYgXj"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}